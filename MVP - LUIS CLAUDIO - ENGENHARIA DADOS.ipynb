{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33782614",
   "metadata": {},
   "source": [
    "# MVP Engenharia de Dados\n",
    "\n",
    "**Nome:** Luis Cl√°udio da Paix√£o Lobato\n",
    "\n",
    "**Matr√≠cula:** 4052025001146\n",
    "\n",
    "**Dataset:** [TISS] (https://dadosabertos.ans.gov.br/FTP/PDA/TISS/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db169e41",
   "metadata": {},
   "source": [
    "# 1Ô∏è‚É£ Objetivo\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105f804",
   "metadata": {},
   "source": [
    "### 1.1 Descri√ß√£o do MVP ###\n",
    "\n",
    "Este MVP tem como objetivo desenvolver um pipeline de dados em nuvem para analisar a evolu√ß√£o do custo m√©dio dos atendimentos ambulatoriais (relativos a determinados procedimentos) e do custo m√©dio das interna√ß√µes (total e por regime de interna√ß√£o), conforme registros do padr√£o TISS ‚Äì Troca de Informa√ß√µes em Sa√∫de Suplementar, no per√≠odo de 2015 a 2024.\n",
    "Na etapa inicial de extra√ß√£o e implementa√ß√£o, foram utilizadas ferramentas como Jupyter-Python e SQL Postgres para coleta e organiza√ß√£o dos dados. Em seguida, o processo foi refinado com tecnologias em nuvem, empregando Databricks e Delta Lake, abrangendo desde a ingest√£o at√© a disponibiliza√ß√£o de dados prontos para an√°lise.\n",
    "O resultado esperado √© uma base estruturada e confi√°vel que permita identificar tend√™ncias, varia√ß√µes e fatores determinantes nos custos de sa√∫de suplementar ao longo do per√≠odo estudado.\n",
    "\n",
    "\n",
    "### 1.2 Problema central ###\n",
    "\n",
    "Atualmente, n√£o h√° uma vis√£o integrada e de f√°cil acesso sobre os custos de interna√ß√£o e atendimento ambulatorial no Brasil. Essa aus√™ncia dificulta a identifica√ß√£o de tend√™ncias, anomalias e dos principais fatores que influenciam a gest√£o da sa√∫de suplementar.\n",
    "Este MVP tem como prop√≥sito suprir essa necessidade, disponibilizando uma base de dados confi√°vel e estruturada, capaz de sustentar an√°lises tanto operacionais quanto estrat√©gicas, e apoiar a tomada de decis√µes mais informadas no setor.\n",
    "\n",
    "\n",
    "\n",
    "### 1.3 Escopo e etapas do pipeline ###\n",
    "\n",
    "- Busca, extra√ß√£o dos arquivos TISS, cruzamento das bases consolidadas e detalhadas para montagem √∫nica das tabelas  mensais/anuais e sele√ß√£o dos procedimentos dos atendimentos ambulatoriais e a base total de interna√ß√£o para o per√≠odo 2015‚Äì2024 ser√° realizada pelo SQL Postgres (cria√ß√£o da camada bronze parte 1).\n",
    "- Ingest√£o e armazenamento: carregamento em Delta Lake para garantir governan√ßa, versionamento e performance.\n",
    "- Modelagem: padroniza√ß√£o, limpeza e harmoniza√ß√£o dos dados (identificadores, datas, valores, procedimentos).\n",
    "- Carga e transforma√ß√£o: cria√ß√£o de camadas (bronze parte 2, silver, gold) para suportar diferentes n√≠veis de consumo.\n",
    "- An√°lise e visualiza√ß√£o: gera√ß√£o de m√©tricas, dashboards e relat√≥rios para identificar padr√µes de gasto, outliers e drivers de custo.\n",
    "\n",
    "### 1.4 Perguntas que o projeto pretende responder ###\n",
    "\n",
    "- Quais s√£o as tend√™ncias temporais de custo m√©dio por tipo de atendimento ambulatorial (por alguns procedimentos) e Interna√ß√£o (total de interna√ß√£o e regime de interna√ß√£o)?\n",
    "\n",
    "\n",
    "### 1.5 Entreg√°veis esperados ###\n",
    "\n",
    "- Base de dados consolidada em Delta Lake cobrindo 2015 ‚Äì 2024.\n",
    "- Conjunto de pipelines automatizados para ingest√£o, transforma√ß√£o e atualiza√ß√£o dos dados.\n",
    "- Dashboards e relat√≥rios anal√≠ticos com indicadores-chave e insights acion√°veis.\n",
    "- Documenta√ß√£o t√©cnica e guia de uso para replica√ß√£o e manuten√ß√£o.\n",
    "Ao final do projeto, espera-se dispor de uma plataforma confi√°vel que permita √† gest√£o p√∫blica e a analistas compreender melhor os determinantes dos custos em sa√∫de no Brasil e apoiar decis√µes baseadas em dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4b95d",
   "metadata": {},
   "source": [
    "# 2Ô∏è‚É£ Fonte dos Dados e Coleta\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ff72e",
   "metadata": {},
   "source": [
    "Os dados utilizados neste projeto foram obtidos exclusivamente de fontes oficiais e p√∫blicas, portanto n√£o h√° restri√ß√µes de confidencialidade. A base principal √© a troca de Informa√ß√µes em Sa√∫de Suplementar (TISS), que re√∫ne registros detalhados sobre atendimentos ambulatoriais e interna√ß√µes em todo o Brasil. O conjunto de dados abrange o per√≠odo de 2015 a 2024 e inclui informa√ß√µes relevantes para an√°lise de custos, procedimentos, prestadores e caracter√≠sticas demogr√°ficas dos atendimentos.\n",
    "\n",
    "### 2.1 Download dos dados e estrutura desses dados\n",
    "\n",
    "Os microdados foram baixados no site da ANS, no seguinte endere√ßo abaixo:\n",
    "Fonte: Troca de Informa√ß√µes em Sa√∫de Suplementar (TISS) ‚Äî https://dadosabertos.ans.gov.br/FTP/PDA/TISS/.\n",
    "\n",
    "Os arquivos foram baixados manualmente, m√™s a m√™s, no formato ZIP, e extra√≠dos para o formato CSV. \n",
    "As informa√ß√µes relativas aos atendimentos assistenciais na Sa√∫de Suplementar s√£o recebidas atrav√©s do Padr√£o TISS e disponibilizadas pela ANS no Portal de Dados Abertos (PDA), por meio dos seguintes conjuntos de dados:\n",
    "\n",
    "- Procedimentos Hospitalares por UF \n",
    "- Procedimentos Ambulatoriais por UF \n",
    "- Modelo de Remunera√ß√£o por UF \n",
    "- Terminologia Unificada da Sa√∫de Suplementar (TUSS) \n",
    "\n",
    "Os dados s√£o apresentados em formato csv e est√£o separados por ano e UF. H√°, ainda, uma planilha com as caracter√≠sticas dos produtos (planos de sa√∫de) referentes aos eventos assistenciais realizados (consultas, exames, interna√ß√µes). As planilhas apresentam os dados consolidados, contendo as informa√ß√µes gerais de cada evento e os dados detalhados, que se referem aos itens assistenciais/procedimentos realizados em cada evento. Assim, para que as duas informa√ß√µes sejam cruzadas deve-se utilizar como chave o ID_EVENTO_ATENCAO_SAUDE. \n",
    "\n",
    "Os itens assistenciais/procedimentos disponibilizados de forma individualizada nos conjuntos de dados Procedimentos Hospitalares por UF e Procedimentos Ambulatoriais por UF est√£o relacionados nas terminologias de OPME e Materiais Especiais, Medicamentos e  Procedimentos e Eventos em Sa√∫de (tabelas 19, 20 e 22 da TUSS, respectivamente). Os grupos dos itens assistenciais/procedimentos disponibilizados de forma agrupada nos conjuntos de dados est√£o relacionados na tabela 63 da TUSS (Grupos de procedimentos e itens assistenciais para envio para ANS). Para verificar se um c√≥digo dessas terminologias est√° dispon√≠vel de forma individualizada ou agrupada, deve-se consultar a tabela 64  (Forma de envio de procedimentos e itens assistenciais para ANS) da TUSS.\n",
    "\n",
    "Os dados detalhados, referentes aos itens assistenciais/procedimentos, quando realizados atrav√©s de um pacote de procedimentos (LG_PACOTE = 1) trar√£o uma linha com o c√≥digo do pacote, que √© criado pela operadora, com as quantidades e valores. As demais linhas trar√£o os itens assistenciais/procedimentos que comp√µem o pacote e sejam de envio individualizado para a ANS, com a tabela de refer√™ncia e o c√≥digo do item assistencial/procedimento de acordo com as tabelas TUSS, mas sem a informa√ß√£o sobre quantidades e valores.\n",
    "\n",
    "Os c√≥digos de diagn√≥stico do conjunto Procedimentos Hospitalares por UF (Hospitalar_CONS) s√£o de envio opcional para a ANS, por determina√ß√£o judicial. Ou seja, nem todos os eventos hospitalares possuem dados de diagn√≥sticos associados.\n",
    "\n",
    "### 2.2 Tabela Fato ‚Äì Interna√ß√£o e Atendimento Ambulatorial \n",
    "\n",
    "As tabelas fato do projeto ‚Äî `internacao_geral_gold` e `ambulatorial_geral_gold` ‚Äî foram geradas a partir dos arquivos de interna√ß√£o e de atendimento ambulatorial disponibilizados no portal de dados abertos da ANS. \n",
    "\n",
    "\n",
    "### 2.3 Tabelas Dimens√£o\n",
    "\n",
    "As tabelas dimens√£o foram obtidas no portal da ANS, e criados manualmente. Foram criadas no formato CSV, separadas por \";\", utilizando um editor de texto. Essas tabelas foram baseadas diretamente nas informa√ß√µes contidas na tabela fato `internacao_geral_gold` e `ambulatorial_geral_gold` e incluem:\n",
    "\n",
    "-\n",
    "\n",
    "-\n",
    "\n",
    "-\n",
    "\n",
    "-\n",
    "\n",
    "-\n",
    "\n",
    "-\n",
    "\n",
    "-\n",
    "\n",
    "-\n",
    "\n",
    "-\n",
    "\n",
    " Essas tabelas foram projetadas para servir de refer√™ncia √†s respectivas colunas nas bases de interna√ß√£o e atendimento ambulatorial, garantindo a integridade dos dados no processo anal√≠tico.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b923920",
   "metadata": {},
   "source": [
    "# 3Ô∏è‚É£ Modelagem e Cat√°logo de Dados\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d84959",
   "metadata": {},
   "source": [
    "Para estruturar e organizar os dados de forma eficiente, foi adotado o Esquema Estrela, um dos modelos mais utilizados em Data Warehousing e Business Intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87671424",
   "metadata": {},
   "source": [
    "### 3.1 Estrutura do Esquema Estrela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9eac6",
   "metadata": {},
   "source": [
    "O esquema estrela do projeto foi constru√≠do com uma tabela fato principal contendo os registros de mortalidade e 7 tabelas dimens√£o para compor as an√°lises. A estrutura ficou organizada da seguinte forma:\n",
    "\n",
    " üìä Tabela Fato: `mortalidade_geral_gold`\n",
    "  \n",
    "  - Esta tabela cont√©m os registros de √≥bitos e √© o n√∫cleo central do esquema. Cada linha representa um √≥bito registrado, com detalhes como data, local, causa da morte e caracter√≠sticas da pessoa falecida.\n",
    "\n",
    "  üìä Tabelas Dimens√£o: `municipios_gold`, `cid_10_gold`, `circunstancia_gold`, `local_obito_gold`, `estado_civil_gold`, `sexo_gold` e `cor_gold`.\n",
    "\n",
    "  - Foram criadas tabelas auxiliares para armazenar descri√ß√µes de vari√°veis categ√≥ricas e facilitar a an√°lise por meio de jun√ß√µes (joins) entre as tabelas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b36b827",
   "metadata": {},
   "source": [
    "### 3.2 Cat√°logo de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f264a",
   "metadata": {},
   "source": [
    "### 3.3 Diagrama Entidade Relacionamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2065ae21",
   "metadata": {},
   "source": [
    "# 4Ô∏è‚É£ Carga\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04094aac",
   "metadata": {},
   "source": [
    "Nesta etapa ser√° feita a carga dos dados para o Delta Lake do Databricks. Ser√° feito um pipeline de ETL (Extra√ß√£o, Transforma√ß√£o e Carga) e todos os processos realizados ser√£o documentados.\n",
    "\n",
    "Inicialmente, importaremos as bibliotecas necess√°rias e criaremos o banco de dados, organizando os dados em tr√™s camadas dentro da arquitetura medallion (Bronze, Silver e Gold). Cada camada ter√° um papel na prepara√ß√£o dos dados:\n",
    "\n",
    "ü•â Camada Bronze: Armazena os dados brutos, exatamente como foram extra√≠dos das fontes originais, sem qualquer modifica√ß√£o.\n",
    "\n",
    "ü•à Camada Silver: Aplica limpeza, padroniza√ß√£o e enriquecimento dos dados, removendo inconsist√™ncias e garantindo a qualidade.\n",
    "\n",
    "ü•á Camada Gold: Otimiza as tabelas para consultas anal√≠ticas e gera√ß√£o de insights para consumo final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd55009",
   "metadata": {},
   "source": [
    "### üíæ 4.1 Banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53833798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################bibliotecas\n",
    "#%pip install pyspark\n",
    "#%pip install matplotlib\n",
    "#%pip install seaborn\n",
    "#%pip install databricks-sdk\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col, when, concat, substring, lit, to_date  # Para manipular dados em spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row  # Para manipular dados em spark\n",
    "import matplotlib.pyplot as plt  # Para plotar gr√°ficos\n",
    "import seaborn as sns  # Para plotar gr√°ficos\n",
    "import pandas as pd  # Para criar dataframes que possam ser lidos pelo matplotlib e seaborn\n",
    "import warnings  # Para desativar warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "####acesso ao databricks\n",
    "from databricks.sdk import WorkspaceClient\n",
    "# Conex√£o com o workspace\n",
    "w = WorkspaceClient(\n",
    "    host=\"https://<sua-instancia>.cloud.databricks.com\",\n",
    "    token=\"dapi218024b5160b80a7aaa24b85fedfcc9a\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59681822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: listar clusters dispon√≠veis\n",
    "for c in w.clusters.list():\n",
    "    print(c.cluster_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff1617",
   "metadata": {},
   "source": [
    "Vamos criar 3 bancos de dados para separar nosso projeto: `bronze`, `silver` e `gold`. Iniciaremos guardando os dados crus no banco de dados `bronze`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5354a73d",
   "metadata": {},
   "source": [
    "### ü•â 4.2 Camada Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8045929",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] O sistema n√£o pode encontrar o arquivo especificado",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m spark = \u001b[43mSparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m spark.sql(\u001b[33m\"\u001b[39m\u001b[33mCREATE DATABASE IF NOT EXISTS bronze\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m spark.sql(\u001b[33m\"\u001b[39m\u001b[33mCREATE DATABASE IF NOT EXISTS silver\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\sql\\session.py:556\u001b[39m, in \u001b[36mSparkSession.Builder.getOrCreate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    554\u001b[39m     sparkConf.set(key, value)\n\u001b[32m    555\u001b[39m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m sc = \u001b[43mSparkContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[32m    559\u001b[39m session = SparkSession(sc, options=\u001b[38;5;28mself\u001b[39m._options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\core\\context.py:523\u001b[39m, in \u001b[36mSparkContext.getOrCreate\u001b[39m\u001b[34m(cls, conf)\u001b[39m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext._lock:\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext._active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext._active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    525\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext._active_spark_context\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\core\\context.py:205\u001b[39m, in \u001b[36mSparkContext.__init__\u001b[39m\u001b[34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway.gateway_parameters.auth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m is not allowed as it is a security risk.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28mself\u001b[39m._do_init(\n\u001b[32m    208\u001b[39m         master,\n\u001b[32m    209\u001b[39m         appName,\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m         memory_profiler_cls,\n\u001b[32m    220\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\core\\context.py:444\u001b[39m, in \u001b[36mSparkContext._ensure_initialized\u001b[39m\u001b[34m(cls, instance, gateway, conf)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext._lock:\n\u001b[32m    443\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext._gateway:\n\u001b[32m--> \u001b[39m\u001b[32m444\u001b[39m         SparkContext._gateway = gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m         SparkContext._jvm = SparkContext._gateway.jvm\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\java_gateway.py:104\u001b[39m, in \u001b[36mlaunch_gateway\u001b[39m\u001b[34m(conf, popen_kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m     proc = Popen(command, **popen_kwargs)\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# preexec_fn not supported on Windows\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     proc = \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proc.poll() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(conn_info_file):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\subprocess.py:1038\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1034\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1035\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1036\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1048\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\subprocess.py:1552\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1550\u001b[39m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[32m   1551\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1552\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1554\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1556\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1561\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1562\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1565\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1566\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[32m   1567\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_pipe_fds(p2cread, p2cwrite,\n\u001b[32m   1568\u001b[39m                          c2pread, c2pwrite,\n\u001b[32m   1569\u001b[39m                          errread, errwrite)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] O sistema n√£o pode encontrar o arquivo especificado"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS bronze\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS silver\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold\")\n",
    "spark.sql(\"SHOW DATABASES\").show()\n",
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0d2c64",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (804728652.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mCREATE DATABASE IF NOT EXISTS bronze;\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Criar um banco de dados chamado 'meu_banco'\n",
    "%sql\n",
    "CREATE DATABASE IF NOT EXISTS bronze;\n",
    "CREATE DATABASE IF NOT EXISTS bilver;\n",
    "CREATE DATABASE IF NOT EXISTS bold;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb3d299",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] O sistema n√£o pode encontrar o arquivo especificado",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Criar sess√£o Spark\u001b[39;00m\n\u001b[32m      4\u001b[39m spark = \u001b[43mSparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTesteLocal\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Exemplo: criar DataFrame\u001b[39;00m\n\u001b[32m      9\u001b[39m df = spark.createDataFrame([(\u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLuis\u001b[39m\u001b[33m\"\u001b[39m), (\u001b[32m2\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMaria\u001b[39m\u001b[33m\"\u001b[39m)], [\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnome\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\sql\\session.py:556\u001b[39m, in \u001b[36mSparkSession.Builder.getOrCreate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    554\u001b[39m     sparkConf.set(key, value)\n\u001b[32m    555\u001b[39m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m sc = \u001b[43mSparkContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[32m    559\u001b[39m session = SparkSession(sc, options=\u001b[38;5;28mself\u001b[39m._options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\core\\context.py:523\u001b[39m, in \u001b[36mSparkContext.getOrCreate\u001b[39m\u001b[34m(cls, conf)\u001b[39m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext._lock:\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext._active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext._active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    525\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext._active_spark_context\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\core\\context.py:205\u001b[39m, in \u001b[36mSparkContext.__init__\u001b[39m\u001b[34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway.gateway_parameters.auth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m is not allowed as it is a security risk.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28mself\u001b[39m._do_init(\n\u001b[32m    208\u001b[39m         master,\n\u001b[32m    209\u001b[39m         appName,\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m         memory_profiler_cls,\n\u001b[32m    220\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\core\\context.py:444\u001b[39m, in \u001b[36mSparkContext._ensure_initialized\u001b[39m\u001b[34m(cls, instance, gateway, conf)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext._lock:\n\u001b[32m    443\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext._gateway:\n\u001b[32m--> \u001b[39m\u001b[32m444\u001b[39m         SparkContext._gateway = gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m         SparkContext._jvm = SparkContext._gateway.jvm\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyspark\\java_gateway.py:104\u001b[39m, in \u001b[36mlaunch_gateway\u001b[39m\u001b[34m(conf, popen_kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m     proc = Popen(command, **popen_kwargs)\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# preexec_fn not supported on Windows\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     proc = \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proc.poll() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(conn_info_file):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\subprocess.py:1038\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1034\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1035\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1036\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1048\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\luis claudio\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\subprocess.py:1552\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1550\u001b[39m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[32m   1551\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1552\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1554\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1556\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1557\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1558\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1561\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1562\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1565\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1566\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[32m   1567\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_pipe_fds(p2cread, p2cwrite,\n\u001b[32m   1568\u001b[39m                          c2pread, c2pwrite,\n\u001b[32m   1569\u001b[39m                          errread, errwrite)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] O sistema n√£o pode encontrar o arquivo especificado"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Criar sess√£o Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TesteLocal\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Exemplo: criar DataFrame\n",
    "df = spark.createDataFrame([(1, \"Luis\"), (2, \"Maria\")], [\"id\", \"nome\"])\n",
    "df.show()\n",
    "\n",
    "# Exemplo: criar banco de dados\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS bronze\")\n",
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
